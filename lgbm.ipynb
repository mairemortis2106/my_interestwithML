{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LoanID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Income</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>MonthsEmployed</th>\n",
       "      <th>NumCreditLines</th>\n",
       "      <th>InterestRate</th>\n",
       "      <th>LoanTerm</th>\n",
       "      <th>DTIRatio</th>\n",
       "      <th>Education</th>\n",
       "      <th>EmploymentType</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>HasMortgage</th>\n",
       "      <th>HasDependents</th>\n",
       "      <th>LoanPurpose</th>\n",
       "      <th>HasCoSigner</th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I38PQUQS96</td>\n",
       "      <td>56</td>\n",
       "      <td>85994</td>\n",
       "      <td>50587</td>\n",
       "      <td>520</td>\n",
       "      <td>80</td>\n",
       "      <td>4</td>\n",
       "      <td>15.23</td>\n",
       "      <td>36</td>\n",
       "      <td>0.44</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Other</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HPSK72WA7R</td>\n",
       "      <td>69</td>\n",
       "      <td>50432</td>\n",
       "      <td>124440</td>\n",
       "      <td>458</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>4.81</td>\n",
       "      <td>60</td>\n",
       "      <td>0.68</td>\n",
       "      <td>Master's</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Married</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Other</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C1OZ6DPJ8Y</td>\n",
       "      <td>46</td>\n",
       "      <td>84208</td>\n",
       "      <td>129188</td>\n",
       "      <td>451</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>21.17</td>\n",
       "      <td>24</td>\n",
       "      <td>0.31</td>\n",
       "      <td>Master's</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Auto</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>V2KKSFM3UN</td>\n",
       "      <td>32</td>\n",
       "      <td>31713</td>\n",
       "      <td>44799</td>\n",
       "      <td>743</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.07</td>\n",
       "      <td>24</td>\n",
       "      <td>0.23</td>\n",
       "      <td>High School</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Married</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Business</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EY08JDHTZP</td>\n",
       "      <td>60</td>\n",
       "      <td>20437</td>\n",
       "      <td>9139</td>\n",
       "      <td>633</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6.51</td>\n",
       "      <td>48</td>\n",
       "      <td>0.73</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Auto</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255342</th>\n",
       "      <td>8C6S86ESGC</td>\n",
       "      <td>19</td>\n",
       "      <td>37979</td>\n",
       "      <td>210682</td>\n",
       "      <td>541</td>\n",
       "      <td>109</td>\n",
       "      <td>4</td>\n",
       "      <td>14.11</td>\n",
       "      <td>12</td>\n",
       "      <td>0.85</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Married</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Other</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255343</th>\n",
       "      <td>98R4KDHNND</td>\n",
       "      <td>32</td>\n",
       "      <td>51953</td>\n",
       "      <td>189899</td>\n",
       "      <td>511</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>11.55</td>\n",
       "      <td>24</td>\n",
       "      <td>0.21</td>\n",
       "      <td>High School</td>\n",
       "      <td>Part-time</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Home</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255344</th>\n",
       "      <td>XQK1UUUNGP</td>\n",
       "      <td>56</td>\n",
       "      <td>84820</td>\n",
       "      <td>208294</td>\n",
       "      <td>597</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>5.29</td>\n",
       "      <td>60</td>\n",
       "      <td>0.50</td>\n",
       "      <td>High School</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Married</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Auto</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255345</th>\n",
       "      <td>JAO28CPL4H</td>\n",
       "      <td>42</td>\n",
       "      <td>85109</td>\n",
       "      <td>60575</td>\n",
       "      <td>809</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>20.90</td>\n",
       "      <td>48</td>\n",
       "      <td>0.44</td>\n",
       "      <td>High School</td>\n",
       "      <td>Part-time</td>\n",
       "      <td>Single</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Other</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255346</th>\n",
       "      <td>ZTH91CGL0B</td>\n",
       "      <td>62</td>\n",
       "      <td>22418</td>\n",
       "      <td>18481</td>\n",
       "      <td>636</td>\n",
       "      <td>113</td>\n",
       "      <td>2</td>\n",
       "      <td>6.73</td>\n",
       "      <td>12</td>\n",
       "      <td>0.48</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Education</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>255347 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            LoanID  Age  Income  LoanAmount  CreditScore  MonthsEmployed  \\\n",
       "0       I38PQUQS96   56   85994       50587          520              80   \n",
       "1       HPSK72WA7R   69   50432      124440          458              15   \n",
       "2       C1OZ6DPJ8Y   46   84208      129188          451              26   \n",
       "3       V2KKSFM3UN   32   31713       44799          743               0   \n",
       "4       EY08JDHTZP   60   20437        9139          633               8   \n",
       "...            ...  ...     ...         ...          ...             ...   \n",
       "255342  8C6S86ESGC   19   37979      210682          541             109   \n",
       "255343  98R4KDHNND   32   51953      189899          511              14   \n",
       "255344  XQK1UUUNGP   56   84820      208294          597              70   \n",
       "255345  JAO28CPL4H   42   85109       60575          809              40   \n",
       "255346  ZTH91CGL0B   62   22418       18481          636             113   \n",
       "\n",
       "        NumCreditLines  InterestRate  LoanTerm  DTIRatio    Education  \\\n",
       "0                    4         15.23        36      0.44   Bachelor's   \n",
       "1                    1          4.81        60      0.68     Master's   \n",
       "2                    3         21.17        24      0.31     Master's   \n",
       "3                    3          7.07        24      0.23  High School   \n",
       "4                    4          6.51        48      0.73   Bachelor's   \n",
       "...                ...           ...       ...       ...          ...   \n",
       "255342               4         14.11        12      0.85   Bachelor's   \n",
       "255343               2         11.55        24      0.21  High School   \n",
       "255344               3          5.29        60      0.50  High School   \n",
       "255345               1         20.90        48      0.44  High School   \n",
       "255346               2          6.73        12      0.48   Bachelor's   \n",
       "\n",
       "       EmploymentType MaritalStatus HasMortgage HasDependents LoanPurpose  \\\n",
       "0           Full-time      Divorced         Yes           Yes       Other   \n",
       "1           Full-time       Married          No            No       Other   \n",
       "2          Unemployed      Divorced         Yes           Yes        Auto   \n",
       "3           Full-time       Married          No            No    Business   \n",
       "4          Unemployed      Divorced          No           Yes        Auto   \n",
       "...               ...           ...         ...           ...         ...   \n",
       "255342      Full-time       Married          No            No       Other   \n",
       "255343      Part-time      Divorced          No            No        Home   \n",
       "255344  Self-employed       Married         Yes           Yes        Auto   \n",
       "255345      Part-time        Single         Yes           Yes       Other   \n",
       "255346     Unemployed      Divorced         Yes            No   Education   \n",
       "\n",
       "       HasCoSigner  Default  \n",
       "0              Yes        0  \n",
       "1              Yes        0  \n",
       "2               No        1  \n",
       "3               No        0  \n",
       "4               No        0  \n",
       "...            ...      ...  \n",
       "255342          No        0  \n",
       "255343          No        1  \n",
       "255344         Yes        0  \n",
       "255345          No        0  \n",
       "255346         Yes        0  \n",
       "\n",
       "[255347 rows x 18 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset/Loan_default.csv',sep=',')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['LoanID'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding data\n",
    "encorder = OrdinalEncoder()\n",
    "for col in df.columns[9:17]:\n",
    "    df[col] = encorder.fit_transform(df[[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 255347 entries, 0 to 255346\n",
      "Data columns (total 17 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   Age             255347 non-null  int64  \n",
      " 1   Income          255347 non-null  int64  \n",
      " 2   LoanAmount      255347 non-null  int64  \n",
      " 3   CreditScore     255347 non-null  int64  \n",
      " 4   MonthsEmployed  255347 non-null  int64  \n",
      " 5   NumCreditLines  255347 non-null  int64  \n",
      " 6   InterestRate    255347 non-null  float64\n",
      " 7   LoanTerm        255347 non-null  int64  \n",
      " 8   DTIRatio        255347 non-null  float64\n",
      " 9   Education       255347 non-null  float64\n",
      " 10  EmploymentType  255347 non-null  float64\n",
      " 11  MaritalStatus   255347 non-null  float64\n",
      " 12  HasMortgage     255347 non-null  float64\n",
      " 13  HasDependents   255347 non-null  float64\n",
      " 14  LoanPurpose     255347 non-null  float64\n",
      " 15  HasCoSigner     255347 non-null  float64\n",
      " 16  Default         255347 non-null  float64\n",
      "dtypes: float64(10), int64(7)\n",
      "memory usage: 33.1 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "cor = df.corr()\n",
    "sns.heatmap(cor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = df.iloc[:,:16], df.iloc[:,16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# coba training + balancing smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalisasi data \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std = StandardScaler()\n",
    "\n",
    "x = std.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# over sampling penerapan \n",
    "from imblearn.over_sampling import SMOTE\n",
    "X_resampled, y_resampled = SMOTE().fit_resample(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Splitting the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 180543, number of negative: 180567\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015407 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 361110, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499967 -> initscore=-0.000133\n",
      "[LightGBM] [Info] Start training from score -0.000133\n"
     ]
    }
   ],
   "source": [
    "# basic lightgbm\n",
    "import lightgbm as lgb\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',  # Gunakan 'multiclass' jika ada lebih dari 2 kelas\n",
    "    'boosting_type': 'gbdt',  # Algoritma boosting (bisa gbdt, dart, goss, etc.)\n",
    "    'metric': 'binary_logloss',  # Metric evaluasi, sesuaikan dengan masalah (misal untuk multiclass: 'multi_logloss')\n",
    "    'num_leaves': 31,  # Sesuaikan dengan dataset, default 31\n",
    "    'learning_rate': 0.5,\n",
    "    'feature_fraction': 0.9  # Subsample fitur\n",
    "}\n",
    "\n",
    "bst = lgb.train(params, train_data, valid_sets=[test_data])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9307140167039589\n",
      "\n",
      "Confusion Matrix:\n",
      " [[44448   679]\n",
      " [ 5576 39575]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.98      0.93     45127\n",
      "         1.0       0.98      0.88      0.93     45151\n",
      "\n",
      "    accuracy                           0.93     90278\n",
      "   macro avg       0.94      0.93      0.93     90278\n",
      "weighted avg       0.94      0.93      0.93     90278\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "predictions = bst.predict(X_test)\n",
    "\n",
    "y_pred_binary = np.where(predictions > 0.5, 1, 0)\n",
    "#Calculating accuracy\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_binary )\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_binary))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001862 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001690 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009713 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002046 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001904 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001878 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002199 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001741 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002686 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002024 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002717 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002966 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002691 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002745 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001819 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002590 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001875 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002715 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002827 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002637 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002409 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002964 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002776 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002602 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003006 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002938 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003060 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002819 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002936 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002592 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002975 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002439 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002593 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001875 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002926 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002940 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002967 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002708 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001912 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002762 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002664 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002777 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002529 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002662 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002842 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003064 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002695 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002947 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001938 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002625 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003256 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002750 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003262 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002620 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002950 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002585 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002844 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001897 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003269 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002754 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011213 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011000 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011457 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001985 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012217 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011695 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012787 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011078 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012671 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012258 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002048 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002561 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002054 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011027 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001977 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012235 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011142 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010752 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002020 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011069 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011956 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012330 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012624 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011078 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011139 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011821 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011155 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010964 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012524 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011085 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010800 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011000 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010863 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013483 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001959 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011221 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013415 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011236 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011748 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009909 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010897 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014401 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011243 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012631 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012687 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012635 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008721 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011031 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010968 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011441 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010935 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011069 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008325 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011055 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011719 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012490 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001885 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001861 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002638 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002587 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002612 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003194 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002728 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002754 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002365 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002531 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002658 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003112 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002832 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002828 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003057 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002776 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002627 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002646 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003195 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002486 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003353 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002807 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002648 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002545 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002454 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001922 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002584 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002419 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002681 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002657 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002239 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002750 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002684 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002822 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002794 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001864 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002638 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001883 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001862 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002675 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002641 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002535 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001953 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001858 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001865 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002957 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002388 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003257 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002997 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002921 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003043 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003004 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002966 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003071 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003130 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001914 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002996 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001930 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003234 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002589 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011203 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001945 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012678 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011002 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010290 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012873 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011489 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010804 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011422 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001945 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002243 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001951 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009908 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010731 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011316 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012484 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010946 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012432 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012777 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010974 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012607 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012610 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011374 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008279 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011388 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007795 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012631 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011269 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011283 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001949 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012344 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010940 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012601 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012694 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001966 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010648 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012143 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011868 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011250 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011226 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012755 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010818 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011081 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011793 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012391 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010724 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010863 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011355 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007767 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012721 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001981 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011933 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012508 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010932 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002070 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003241 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003064 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002990 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003459 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002766 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003126 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002662 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002088 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002817 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002478 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002607 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001933 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001872 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002558 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002446 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001860 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002491 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002842 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003034 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003096 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002860 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002915 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002684 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001891 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003010 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001914 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002864 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002681 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002852 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002659 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002618 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002684 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002951 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001872 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003103 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002594 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003385 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002886 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001873 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002832 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002679 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002716 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002604 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002881 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002685 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002611 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001928 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002753 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002613 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001867 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002760 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002242 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002717 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002877 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003067 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001908 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002932 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001898 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002651 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008809 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007433 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011462 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014218 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012532 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012553 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010989 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017303 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011082 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011930 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013721 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010833 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012405 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011534 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011238 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011584 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012734 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011217 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012712 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010904 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012604 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011071 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001975 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008391 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011017 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010710 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013868 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011986 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010550 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001967 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012689 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012554 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011438 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001976 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012451 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010330 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009662 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012852 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001989 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011332 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012784 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010896 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010875 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012650 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012579 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002007 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007942 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007924 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012620 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010735 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011562 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011054 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011008 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012295 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011122 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001446 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001897 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001912 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001400 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001910 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001933 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001608 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001822 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001394 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001789 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001974 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001819 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001764 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001928 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001982 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001930 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001908 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001753 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003468 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001385 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001769 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001649 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002473 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001797 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003411 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001726 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002818 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001739 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003219 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002697 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002853 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007422 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002791 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010910 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001942 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001906 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001787 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002140 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001759 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003161 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003115 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001920 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001925 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001785 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002704 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001923 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001890 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002971 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001436 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002723 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009914 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003076 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002502 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001507 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001870 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001792 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002969 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001777 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002856 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001745 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012333 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008474 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013056 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011395 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012607 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012595 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012686 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011615 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012497 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012479 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012675 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011772 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012884 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012587 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011962 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011420 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010864 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012752 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001968 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012725 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011273 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014508 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010875 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010927 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011061 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012651 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011310 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013663 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011478 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013590 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015300 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012727 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012652 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011351 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012847 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010417 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011030 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001933 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011390 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012723 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012337 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012957 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012814 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002062 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001986 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013343 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010310 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009794 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012023 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011235 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012790 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011707 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008599 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162489, number of negative: 162510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011084 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499968 -> initscore=-0.000129\n",
      "[LightGBM] [Info] Start training from score -0.000129\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012978 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012715 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 162488, number of negative: 162511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012591 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 324999, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499965 -> initscore=-0.000142\n",
      "[LightGBM] [Info] Start training from score -0.000142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Info] Number of positive: 180543, number of negative: 180567\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002515 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4076\n",
      "[LightGBM] [Info] Number of data points in the train set: 361110, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499967 -> initscore=-0.000133\n",
      "[LightGBM] [Info] Start training from score -0.000133\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=LGBMClassifier(), n_jobs=1,\n",
       "             param_grid={&#x27;boosting_type&#x27;: [&#x27;gbdt&#x27;, &#x27;dart&#x27;, &#x27;goss&#x27;, &#x27;rf&#x27;],\n",
       "                         &#x27;feature_fraction&#x27;: [0.5, 0.9],\n",
       "                         &#x27;learning_rate&#x27;: [0.01, 0.05, 0.5],\n",
       "                         &#x27;metric&#x27;: [&#x27;binary_logloss&#x27;], &#x27;num_leaves&#x27;: [10, 30],\n",
       "                         &#x27;objective&#x27;: [&#x27;binary&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=LGBMClassifier(), n_jobs=1,\n",
       "             param_grid={&#x27;boosting_type&#x27;: [&#x27;gbdt&#x27;, &#x27;dart&#x27;, &#x27;goss&#x27;, &#x27;rf&#x27;],\n",
       "                         &#x27;feature_fraction&#x27;: [0.5, 0.9],\n",
       "                         &#x27;learning_rate&#x27;: [0.01, 0.05, 0.5],\n",
       "                         &#x27;metric&#x27;: [&#x27;binary_logloss&#x27;], &#x27;num_leaves&#x27;: [10, 30],\n",
       "                         &#x27;objective&#x27;: [&#x27;binary&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LGBMClassifier(), n_jobs=1,\n",
       "             param_grid={'boosting_type': ['gbdt', 'dart', 'goss', 'rf'],\n",
       "                         'feature_fraction': [0.5, 0.9],\n",
       "                         'learning_rate': [0.01, 0.05, 0.5],\n",
       "                         'metric': ['binary_logloss'], 'num_leaves': [10, 30],\n",
       "                         'objective': ['binary']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training dengna hyperparameter\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'objective': ['binary'],  # Gunakan 'multiclass' jika ada lebih dari 2 kelas\n",
    "    'boosting_type': ['gbdt','dart','goss','rf'],  # Algoritma boosting (bisa gbdt, dart, goss, etc.)\n",
    "    'metric': ['binary_logloss'],  # Metric evaluasi, sesuaikan dengan masalah (misal untuk multiclass: 'multi_logloss')\n",
    "    'num_leaves': [10,30],  # Sesuaikan dengan dataset, default 31\n",
    "    'learning_rate': [0.01,0.05,0.5],\n",
    "    'feature_fraction': [0.5,0.9]  # Subsample fitur\n",
    "}\n",
    "lighbm = lgb.LGBMClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator= lighbm,\n",
    "    param_grid=params,\n",
    "    scoring='accuracy',\n",
    "    n_jobs = 1,\n",
    "    cv = 10\n",
    ")\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter terbaik: {'boosting_type': 'dart', 'feature_fraction': 0.5, 'learning_rate': 0.5, 'metric': 'binary_logloss', 'num_leaves': 30, 'objective': 'binary'}\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "Akurasi: 0.9332727796362348\n",
      "\n",
      "Confusion Matrix:\n",
      " [[44830   297]\n",
      " [ 5727 39424]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.99      0.94     45127\n",
      "         1.0       0.99      0.87      0.93     45151\n",
      "\n",
      "    accuracy                           0.93     90278\n",
      "   macro avg       0.94      0.93      0.93     90278\n",
      "weighted avg       0.94      0.93      0.93     90278\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Parameter terbaik:\", grid_search.best_params_)\n",
    "\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "print(\"Akurasi:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# coba information gain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Feature  Information Gain\n",
      "15     HasCoSigner          0.035968\n",
      "13   HasDependents          0.035364\n",
      "12     HasMortgage          0.033480\n",
      "11   MaritalStatus          0.018825\n",
      "0              Age          0.014930\n",
      "10  EmploymentType          0.010932\n",
      "9        Education          0.010399\n",
      "5   NumCreditLines          0.010348\n",
      "14     LoanPurpose          0.010024\n",
      "7         LoanTerm          0.008547\n",
      "6     InterestRate          0.008403\n",
      "1           Income          0.007627\n",
      "4   MonthsEmployed          0.005519\n",
      "2       LoanAmount          0.004010\n",
      "3      CreditScore          0.001036\n",
      "8         DTIRatio          0.000831\n"
     ]
    }
   ],
   "source": [
    "# menggunakan information gain \n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# Menghitung information gain\n",
    "info_gain = mutual_info_classif(x,y, discrete_features='auto',n_neighbors=3, copy=True, random_state=None)\n",
    "\n",
    "# Menyajikan hasil dalam bentuk dataframe\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': x.columns,\n",
    "    'Information Gain': info_gain\n",
    "}).sort_values(by='Information Gain', ascending=False)\n",
    "\n",
    "# Menampilkan fitur dan nilai Information Gain\n",
    "print(feature_importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitur yang dipilih: ['Age', 'Income', 'LoanAmount', 'MonthsEmployed', 'InterestRate']\n"
     ]
    }
   ],
   "source": [
    "# menggunakan chi square\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# Seleksi fitur terbaik berdasarkan uji chi-square\n",
    "select_k_best = SelectKBest(chi2, k=5)  # Pilih 5 fitur terbaik\n",
    "X_new = select_k_best.fit_transform(x, y)\n",
    "\n",
    "# Mengambil boolean array yang menunjukkan fitur yang dipilih\n",
    "selected_features_mask = select_k_best.get_support()\n",
    "\n",
    "# Mengambil nama fitur yang dipilih\n",
    "selected_features = x.columns[selected_features_mask]\n",
    "\n",
    "# Mencetak fitur yang dipilih\n",
    "print(f\"Fitur yang dipilih: {selected_features.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Age        Income    LoanAmount  CreditScore  MonthsEmployed  \\\n",
      "PC1  4.681284e-07  6.823556e-04 -9.999998e-01    -0.000003       -0.000001   \n",
      "PC2  4.796979e-07 -9.999998e-01 -6.823556e-04     0.000006       -0.000002   \n",
      "PC3 -5.208098e-05  5.829186e-06 -2.826702e-06     1.000000        0.000140   \n",
      "PC4  1.765299e-04  2.381721e-06  1.377878e-06     0.000140       -1.000000   \n",
      "PC5 -1.076702e-03 -4.319740e-07  6.078419e-07     0.000122       -0.000755   \n",
      "\n",
      "     NumCreditLines  InterestRate      LoanTerm      DTIRatio     Education  \\\n",
      "PC1   -1.253812e-08  2.145537e-07 -6.080391e-07 -3.658457e-09 -4.028932e-08   \n",
      "PC2    5.777957e-08  3.928194e-07  4.333677e-07 -1.226142e-09  2.760868e-08   \n",
      "PC3    8.575728e-08  1.823066e-05  1.216011e-04 -1.511708e-06  1.476408e-06   \n",
      "PC4   -4.100570e-05 -2.141044e-05  7.548588e-04 -1.173947e-05  4.226247e-05   \n",
      "PC5    1.512668e-05 -4.128219e-04 -9.999990e-01 -3.089423e-05  1.992404e-04   \n",
      "\n",
      "     EmploymentType  MaritalStatus   HasMortgage  HasDependents   LoanPurpose  \\\n",
      "PC1   -4.829303e-08   8.879313e-09  5.650283e-09  -9.864870e-10 -1.145467e-09   \n",
      "PC2    1.474694e-07  -1.332540e-08  1.213475e-08   2.014039e-08  7.584659e-08   \n",
      "PC3    2.455685e-05  -1.651508e-05  5.437563e-06  -9.503622e-06  5.271346e-06   \n",
      "PC4   -1.829605e-05   2.176034e-06 -3.076025e-06  -2.099683e-05  1.052071e-04   \n",
      "PC5   -5.054040e-05   5.005246e-05 -5.233194e-05  -7.140306e-05 -2.390270e-04   \n",
      "\n",
      "      HasCoSigner  \n",
      "PC1  1.303381e-08  \n",
      "PC2  4.524600e-08  \n",
      "PC3 -8.677089e-06  \n",
      "PC4 -1.533534e-05  \n",
      "PC5  3.432106e-05  \n",
      "Explained variance ratio: [7.67745671e-01 2.32250196e-01 3.86294781e-06 1.83605359e-07\n",
      " 4.40531043e-08]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Reduksi dimensi menggunakan PCA\n",
    "pca = PCA(n_components=5)  # Memilih 5 komponen utama\n",
    "X_pca = pca.fit_transform(x)\n",
    "\n",
    "# Membuat DataFrame untuk menampilkan kontribusi fitur terhadap komponen\n",
    "pca_components = pd.DataFrame(\n",
    "    pca.components_, \n",
    "    columns=x.columns,  # Nama kolom sesuai dengan fitur asli\n",
    "    index=[f'PC{i+1}' for i in range(pca.n_components_)]  # Nama komponen utama\n",
    ")\n",
    "\n",
    "# Tampilkan kontribusi (loading matrix)\n",
    "print(pca_components)\n",
    "\n",
    "print(f'Explained variance ratio: {pca.explained_variance_ratio_}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
